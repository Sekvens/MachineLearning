Machine learning assignment 2

Plot1: Different learning values.

Question 1:
The algorithm finds a local minimum before the global minimum and get stuck at that local minimum.

Question 2:
A low learning rate increases the risk of getting stuck at local minima. A high learning rate would increases the probability that it jumps over a particular local minimum, especially if it have a narrow valley. However if the local minimum is very wide the algorithm will be likely to start oscillating between the sides of the valley. If the algorithm with a high learning rate early on gets very close to the global minimum it might adjust the weights favourably enough to very fast narrowing down to the global minimum. However the same goes for the algorithm with a low learning rate. 
We believe that there is no optimal general value that works for all problems. The learning rate have to be tweaked depending on the problem space.

Question 3:
The range of the hyperbolic tangent function is between $[-1, - 1]$ and the range of the logistic function is between $[0, 1]$ which is the functions we used for the hidden layer and respectively the output layer. 

Question 4:
Because the weights are randomized for each run.

Question 5:
H1 = AND, H2 = OR, O = XOR

Question 6: // Need to verify the it with a truth table or similar.

Plot3

Question 7:
The biggest difference is the difference in number of epoch needed. Resilient back propagation needs a lot fewer epoch to reach a minima.
We think that resilient back propagation is better suitable for this problem since it finds a minimum in about 400 times less epochs compare to the normal back propagation.
A interesting observation from using plot_xor is that the way rprop have classified the groups is a mirrored image of the bprop. 

Question 8:
With many epochs we notice that the higher number of nodes we have the less MSE we get. We suspect that they can faster tweak the curve to cross the desired coordinates since they have more options to optimize. 

Question 9:
The 6 node network got the approximation that looks most like the desired function. It seems like 3 nodes is not enough to make a plot close to the training targets. Each node represents a hyper plane and it seems like 3 hyper planes is not enough to plot the actual target nodes. It seems like the networks with bigger size tend to have to much freedom between the training targets to plot a way towards them. Somehow the size of 6 nodes seems to limit the shape of the curve to represent the desired function plot. However if we had more target nodes we would probably need more nodes in the network. 

Question 10:
With few hidden nodes we get to few hyper planes to classify the actual target nodes in this problem. 

Question 11:
If we have to many hidden nodes the errors are getting better but the approximation towards the function is suffering. There are to many hyperplanes that it can adjust so it's not that likely that it will plot it as a smooth curve between the target nodes. Instead it just get rewards for reaching the target nodes, not caring about the extra hyper planes between the target nodes.

Question 12:
We know that the hyperbolic tangent function can only create a few types of hyperplanes. By looking at the desired function we can imagine how many hyperplanes we need to get a good approximation of it. For every hyperplane we need one hidden node to the MLP.

Question 13:
With rback propagation we get very fast a result that is quite similar to the desired function shape. However if we let it run for a long time it doesn't really get any better. If we want more precision we can use normal back propagation but the shape will be more distorted the first iterations but quite fast it will catch up and become better than the rprop.

Question 14:
We used 50 nodes and rback prop. We used 3000 epochs and delta0 = 0.07, delt_int = 1.2, delt_dec = 0.5, maximum_delta 50.

Question 15

With the same network but with normalized data, the algorithm seems to succeed 
much more frequently on training the network. With the original data the algorithm
successfully managed to train the network one time every 10 training sessions. 
With the normalized data, the algorithm seems to succeed every run, even with 
much fewer nodes. We tried a network with only three nodes instead of 50, and
it still successfully trained the network in very few epochs.

Question 16

Normalizing the values to the range of the activation funtion of the hidden layer is 
obviously a good idea. We use the tangent hyperbolic funtion wich has a range of
[-1,1]. Normalizing should be used with caution though, as it discards information. 
We do not know if some kind of values that are more important for the classifition, 
and in that case normalizing them will possible make training harder. As we have
seen, this was not the case in this problem.

Question 17

Considering the cases where the algorithm was able to train the network in a 
significant number of epochs: 
The training set usually has the lowest error rate, since it is the data we use 
to adjust the weights with. The validation usually has the second lowest 
error rate and the test the highest error rate. The reason the validation data
is biased is that it is that even though it is not used to adjust the wieghts,
it is used to select the final model of the network. The test data is the 
completely unbiased data, which means it usually has the highest error rate. 
In general, this means that even though a network seems to be well trained, 
it might not perform as good when given fresh data.

Question 18

In early epochs, the test and validation set is behaving quite randomly. This is 
because an untrained network is random. After a while, the curves becomes 
more smooth. After a more significant number of epochs, the validation curve
has minimum after wich its error starts to steadily increase. At this point
we know we should stop training in order to prevent over-fitting. In the example 
plot, we chose the maximum number of epochs where the validation error could 
increase as 1000, so we continue training for maximum 1000 epochs after we find a 
minimum in the validation graph. The test set error usually doesn't get much 
smaller as we train the network for a long time. A well trained network should
perform well when given fresh data but perhaps the data set was too small or 
the training method was wrong.

Question 19

1. Training the network long does not neccesarily mean that it is going to be 
giving the correct outputs when given inputs outside the training set, which 
is what we want in most cases. 
2. We need to be careful when deciding when to stop training. Because of the 
nature of a NN, having a few failed validation epochs does not mean we already 
found the optiml solution, so we cant stop training too early. We can also not 
stop training too late, because that will result in a overfitted NN which will 
perform bad on data that was not in the original training set. 




