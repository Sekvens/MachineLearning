
\section{Preparing the data}

\subsection{Preprocessing}

Different kind of messages has different structure, properties and
metadata. In this report, we'll assume that the only interesting part of an
message is it's plain text content. Before we attempt to get any useful
information from this content, we'll
need to prepare the content string in various ways. There are different
measures one can take to make a string easier to analyse, for example filter
out stop words \cite{stop-words} or lemmatization \cite{lemmatization}.

\subsection{Lemmatization} Lemmatization is a way of changing the words into
it's basic form. This have been proven very useful according to some guy when
handling data. Maybe it was
\cite{tretyakov2004machine}.

\subsection{Feature Extraction}

The plain text describing the content of a message is a string.
Strings are, unfortunately not an object a ANN can handle in a good
way. Most ANN works with numeric vectors, and are trying to create a hyperplane
between them in order separate classes in input space. We need therefore
convert the strings into numerical vectors. How to do this is not obvious,
but regardless of technique chosen for doing this, we'll lose
information in the process. If we extract features so that there may exist a
spam message with the same feature vector as a legitimate message, the spam
detector will always make mistakes. On the other hand, a too complicated choice
of feature vector could also make classification difficult. Unfortunately, the
problem of choosing the right feature vector for a machine learning method
doesn't seem to have gotten enough attention, and we were not able to find many
papers discussing the problem. Given this, we needed to come up with the
feature extraction techniques ourselves. There were two alternatives:
\begin{enumerate}
  \item Acquire a list $L$ of all $N$ possible words. Allocate a vector $V$
    of length $N$. For each word of a given the message: Find the message in
    $L$.  If the word is on index $i$ in the list, then set $V[i]$ to 1.0. Set
    the remaining elements to 0.0.
  \item Extract various numeric properties of the message (average word length,
    word diversity, average sentence length), create a vector from these
    numbers.
\end{enumerate}

After analysing spam messages manually, we realized that many of the
words in a spam message didn't make sense and wouldn't match against any
dictionary. Since the beginning of spam messages a common technique to surpass
filters has been by using specially spelled words (e.g. (B-U-Y N-O-W) or simply
misspelled words like (BUUY NOOW). \cite{machine-learning-methods-spam}
Furthermore, we believe that it isn't neccecarily the individual words of a
message that classifies it a spam message or a legitimate message. As it really
is the context behind the words that needs to be computed, we'll
need to extract more abstract properties about a messages without losing too
much information.
Considering this, and realizing that the $N$ in \#$1$ in the above
list would be probably be really large, we chose the approach \#$2$.

