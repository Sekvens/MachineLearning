
\section{Preparing the data}

\subsection{Preprocessing}

Different kind of messages has different structure, properties and
metadata. In this report, we'll assume that the only interesting part of an
message is it's plain text content. Before we attempt to get any useful
information from this content, we'll
need to prepare the content string in various ways. There are different
measures one can take to make a string easier to analyse, for example filter
out stop words \cite{stop-words} or lemmatization \cite{lemmatization}.


\subsection{Feature Extraction}

The plain text describing the content of a message is a string.  Strings are,
unfortunately not an object a ANN can handle in a good way. Most ANN works with
numeric vectors, and therefore we need to convert the strings into numerical
vectors. How to do this is not obvious, but regardless of technique chosen for
doing this, we'll lose information in the process. If we extract features so
that there may exist a spam message with the same feature vector as a
legitimate message, the spam detector will always make mistakes. On the other
hand, a too complicated choice of feature vector could also make classification
difficult. Unfortunately, the problem of choosing the right feature vector for
a machine learning method doesn't seem to have gotten enough attention, and we
were not able to find many papers discussing the problem. Given this, we needed
to come up with the feature extraction techniques ourselves. There were two
alternatives:
\begin{enumerate}
  \item Acquire a list $L$ of all $N$ possible words. Allocate a vector $V$
    of length $N$. For each word of a given the message: Find the message in
    $L$.  If the word is on index $i$ in the list, then set $V[i]$ to 1.0. Set
    the remaining elements to 0.0.
  \item Extract various numeric properties of the message (average word length,
    word diversity, average sentence length), create a vector from these
    numbers.
\end{enumerate}

\subsection{Choice of feature vector and hypotheses}
After analysing spam messages manually, we realized that many of the
words in a spam message didn't make sense and wouldn't match against any
dictionary. A common technique among spammers in order to surpass
filters has been by obfuscating the mail content by using specially spelled
words (e.g. (B-U-Y N-O-W) or simply misspelled words like (BUUY NOOW)
\cite{machine-learning-methods-spam}. Furthermore, we believe that it isn't
necessarily the individual words of a message that classifies it a spam message
or a legitimate message. As it really is the context behind the words that
needs to be computed, we'll need to extract more abstract properties about a
messages without losing too much information.
Considering this, and realizing that the $N$ in \#$1$ in the above
list would be probably be really large, we chose the approach \#$2$. Since we
did not know which properties of a message might help to classify it as spam or
legitimate, the approach was to first acquire a large set of features and then
attempt to improve the set and perhaps filter out redundant features. The
initial features are listed under Feature List 1. 

